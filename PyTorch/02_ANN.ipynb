{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fecdb080-b770-412d-958e-15a41b089ba7",
   "metadata": {},
   "source": [
    "## PyTorch - Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93ffab2e-5e7b-4243-9f66-081155b3da5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24c6cb0a-5828-49c6-8c43-630ef83a1804",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "#We can check whether we have gpu\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e92c72-4133-4fa2-b29a-dd7946f250ad",
   "metadata": {},
   "source": [
    "Let's have linear regression as a case study to study the different components of PyTorch. These are the following components we will be covering:\n",
    "\n",
    "1. Specifying input and target\n",
    "2. Dataset and DataLoader\n",
    "3. `nn.Linear` (Dense)\n",
    "4. Define loss function\n",
    "5. Define optimizer function\n",
    "6. Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1888eab-5207-427c-818a-b2af18efa70a",
   "metadata": {},
   "source": [
    "### 1. Specifiying input and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4dc9759-1398-4e07-bbc1-aadbd7d0f120",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([15, 3]), torch.Size([15, 2]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input (temp, rainfall, humidity)\n",
    "X_train = np.array([[73, 67, 43], [91, 88, 64], [87, 134, 58], \n",
    "                   [102, 43, 37], [69, 96, 70], [73, 67, 43], \n",
    "                   [91, 88, 64], [87, 134, 58], [102, 43, 37], \n",
    "                   [69, 96, 70], [73, 67, 43], [91, 88, 64], \n",
    "                   [87, 134, 58], [102, 43, 37], [69, 96, 70]], \n",
    "                  dtype='float32')\n",
    "\n",
    "# Targets (apples, oranges)\n",
    "Y_train = np.array([[56, 70], [81, 101], [119, 133], \n",
    "                    [22, 37], [103, 119], [56, 70], \n",
    "                    [81, 101], [119, 133], [22, 37], \n",
    "                    [103, 119], [56, 70], [81, 101], \n",
    "                    [119, 133], [22, 37], [103, 119]], \n",
    "                   dtype='float32')\n",
    "\n",
    "# tensors from these to numpy array\n",
    "# torch.form_numpy (copy) or torch.tensor (not a copy!)\n",
    "# inputs = torch.tensor(X_train)\n",
    "# targets = torch.tensor(Y_train)\n",
    "inputs = torch.from_numpy(X_train)\n",
    "targets = torch.from_numpy(Y_train)\n",
    "\n",
    "# print the shape of these tensors\n",
    "# use either .size() or .shape\n",
    "inputs.shape, targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52eea6b8-3c14-4bd5-a8d2-32143ecbb0ae",
   "metadata": {},
   "source": [
    "### 2. Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e20a35-0ef2-4e71-8741-109526de1b8c",
   "metadata": {},
   "source": [
    "We'll create a `TensorDataset`, which allows access to rows from inputs and targets as tuples, and if we want to use `DataLoader` (will talk shortly) from numpy array, we have to first make `TensorDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0382b4ef-6c57-41d8-935b-868a7eafcfa9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7db329e-0cdd-468b-b9c8-b3d84e5064fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([73., 67., 43.]), tensor([56., 70.]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put this dataset on top of our inputs and targets\n",
    "# format: TensorDataset(X, y) where X.shape is (m, n) and y.shape is (m, k)\n",
    "ds = TensorDataset(inputs, targets)\n",
    "ds[0] # this is a tuple of two tensors, the x and the corresponding y \n",
    "# this IS THE FORMAT that PyTorch wants!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "822319d9-e830-4f0e-ab4a-d479c92a4808",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([73., 67., 43.]), tensor([56., 70.]))\n"
     ]
    }
   ],
   "source": [
    "#The data loader is typically used in a for-in loop. Let's look at an example\n",
    "for i in ds:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63566053-3618-443e-972d-74290645e87f",
   "metadata": {},
   "source": [
    "### DataLoader\n",
    "\n",
    "By default, PyTorch works in batch (remember the mini-batch gradient descent!).\n",
    "In simple words, it will ALWAYS take some mini-batch, and perform gradient descent.\n",
    "Why PyTorch assume mini-batch; because PyTorch assumes you won't be able to fit in ~1M samples into your GPU ram ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a44ba42-02cb-4cdc-b232-009ac0336a5a",
   "metadata": {},
   "source": [
    "We'll now create a `DataLoader`, which can split the data into batches of a predefined size while training. It also provides other utilities like shuffling and random sampling of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef88009e-78c5-4587-84a5-b038d6d4e06d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this dataloader will automatically create an enumerator, look at each batch\n",
    "# means, you can simply perform a for loop onto this dataloader\n",
    "# if you DON'T WANT TO use this DataLoader, it's fine! but you have\n",
    "# to manually select the mini-batch (just like we do in our LR mini-batch class)\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "208825b8-8497-459a-a9e4-c3b2eb14e3c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define data loader\n",
    "batch_size = 3 # this is any number you like\n",
    "#too small then your code runs slow\n",
    "#too big then you may get \"out of memory\" error\n",
    "dl = DataLoader(ds, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4d589a3-3df7-426a-bcdb-20f090fd21d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 69.,  96.,  70.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [ 91.,  88.,  64.]]), tensor([[103., 119.],\n",
      "        [119., 133.],\n",
      "        [ 81., 101.]])]\n"
     ]
    }
   ],
   "source": [
    "# now, this dl is basically an enumerator, in which we can loop on ....\n",
    "for something in dl:\n",
    "    print(something)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdb8b31d-d611-4d62-acad-48d0df1e8e8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([[ 69.,  96.,  70.],\n",
      "        [ 73.,  67.,  43.],\n",
      "        [102.,  43.,  37.]])\n",
      "Y: tensor([[103., 119.],\n",
      "        [ 56.,  70.],\n",
      "        [ 22.,  37.]])\n"
     ]
    }
   ],
   "source": [
    "for x, y in dl:\n",
    "    print(f\"X: {x}\")\n",
    "    print(f\"Y: {y}\")\n",
    "    break\n",
    "\n",
    "#this dl keep on running; which is intentional; because  we have the concept of \"epochs\"\n",
    "#\"epochs\" means that how many times we \"exhaust\" the whole dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5031f2-46b8-465e-9bc6-9a95a850203a",
   "metadata": {},
   "source": [
    "## 3. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acbfe9c-4725-4337-8d25-11a17d006d96",
   "metadata": {},
   "source": [
    "### 3.1 Define our neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40021f62-9eec-448f-b9e0-b56c9a0bc18d",
   "metadata": {},
   "source": [
    "Instead of initializing the weights & biases manually, we can define the model using the `nn.Linear` class from PyTorch, which does it automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c9883ff-febb-40b2-bc82-9fead86148e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.3479, -0.0461,  0.2091],\n",
      "        [ 0.2365,  0.2009,  0.4819]], requires_grad=True)\n",
      "torch.Size([2, 3])\n",
      "Parameter containing:\n",
      "tensor([ 0.0682, -0.2729], requires_grad=True)\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn   # stands for neural network; modules that contains many possible layer\n",
    "\n",
    "# Define model\n",
    "# format: nn.Linear(in_features, out_features)\n",
    "# format: nn.Linear(temp;rainfall;hum , orange;apples)\n",
    "model = nn.Linear(3, 2)  #nn.Linear assume this shape (in_features, out_features)\n",
    "print(model.weight)  #by default, these weight are uniformly close to 0\n",
    "print(model.weight.size()) # (out_features, in_features)\n",
    "print(model.bias)\n",
    "print(model.bias.size()) #(out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee676e7a-b9a4-4fd2-b0c6-de2dd01d3097",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.4408,  0.8783,  0.7804],\n",
       "         [-0.2983,  0.7925,  0.9063]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0636, -0.2776], requires_grad=True)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters\n",
    "list(model.parameters())  #model.param returns a generator # weight and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f81cf59-ee0a-4f6f-ba41-acace09f2b39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "#we can print the complexity by the number of parameters\n",
    "#p.numel() just flatten everything...\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "# 6 weights and 2 bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0f668a4-eb08-432d-bd13-86a1b3d0984a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 60.2941,  70.0181],\n",
       "        [ 87.1939, 100.3242],\n",
       "        [124.6786, 132.5363],\n",
       "        [ 21.7492,  36.9094],\n",
       "        [108.5999, 118.6643],\n",
       "        [ 60.2941,  70.0181],\n",
       "        [ 87.1939, 100.3242],\n",
       "        [124.6786, 132.5363],\n",
       "        [ 21.7492,  36.9094],\n",
       "        [108.5999, 118.6643],\n",
       "        [ 60.2941,  70.0181],\n",
       "        [ 87.1939, 100.3242],\n",
       "        [124.6786, 132.5363],\n",
       "        [ 21.7492,  36.9094],\n",
       "        [108.5999, 118.6643]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate predictions, perform a forward pass\n",
    "# format: model(inputs)\n",
    "preds = model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dc797a-02de-44e7-b633-014e18399f0e",
   "metadata": {},
   "source": [
    "### 3.2 Define the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80cae3b3-78b4-4a0b-bcb2-6952bc7f783b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6051.5464, grad_fn=<MseLossBackward0>)\n",
      "6051.54638671875\n"
     ]
    }
   ],
   "source": [
    "criterion_mse = nn.MSELoss()\n",
    "mse = criterion_mse(preds, targets)\n",
    "print(mse)\n",
    "print(mse.item())  ##print out the loss number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a56549-9cc8-4245-92ce-952d581b902e",
   "metadata": {},
   "source": [
    "### 3.3 Define the optimizer\n",
    "\n",
    "* Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25686470-2500-4bca-bad2-74b5b517b42c",
   "metadata": {},
   "source": [
    "We use `optim.SGD` to perform stochastic gradient descent where samples are selected in batches (often with random shuffling) instead of as a single group. Note that `model.parameters()` is passed as an argument to `optim.SGD`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d315b88b-0e01-4e20-81fe-3bc47ae72920",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "#momentum update the weight based on past gradients also, which will be useful for getting out of local max/min\n",
    "#If our momentum parameter was $0.9$, we would get our current grad + the multiplication of the gradient \n",
    "#from one time step ago by $0.9$, the one from two time steps ago by $0.9^2 = 0.81$, etc.\n",
    "opt = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcca05a-b72e-4d2f-8230-e5a292ba70df",
   "metadata": {},
   "source": [
    "### 3.4 Actually train the model\n",
    "\n",
    "- 1. Predict\n",
    "- 2. Loss\n",
    "- 3. Gradient\n",
    "- 4. Update the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8bec3adc-8bc7-465a-9f98-4db201cfd4b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Utility function to train the model\n",
    "def fit(num_epochs, model, loss_fn, opt, train_dl):\n",
    "    \n",
    "    # Repeat for given number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # Train with batches of data\n",
    "        for xb,yb in train_dl:\n",
    "            #x and y are the minibatch of X_train and y_train (batch size=3)\n",
    "            #x and y will have 3 samples each, but the number of features are the same!!\n",
    "            \n",
    "            xb.to(device) #move them to gpu if possible, if not, it will be cpu  (batch, features) = (3, 3)\n",
    "            yb.to(device)                    # (batch, target) = (3, 2)\n",
    "                    \n",
    "            # 1. Predict (forward pass)\n",
    "            pred = model(xb)\n",
    "                      \n",
    "            # 2. Calculate loss\n",
    "            loss = loss_fn(pred, yb)\n",
    "            \n",
    "            # 3. Calculate gradient\n",
    "            # 3.1 clear out the previous gradients\n",
    "            # format: optimizer.zero_grad()\n",
    "            opt.zero_grad()  #if not, the gradients will accumulate\n",
    "            \n",
    "            # 3.2 call backward() on loss to retrieve all the gradients (backpropagation)\n",
    "            loss.backward()   #why called backward on loss??\n",
    "            #backward DOED NOT adjust the weight YET... just backpropagation\n",
    "            #we want to calculate the gradients of all parameters\n",
    "            #IN RESPECT TO THELOSS\n",
    "            \n",
    "            # Print out the gradients.\n",
    "            #print ('dL/dw: ', model.weight.grad) \n",
    "            #print ('dL/db: ', model.bias.grad)\n",
    "            \n",
    "            # 4. Update parameters using gradients\n",
    "            opt.step()\n",
    "            \n",
    "        # Print the progress\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            sys.stdout.write(\"\\rEpoch [{}/{}], Loss: {:.4f}\".format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "687d950c-b637-46f0-9a7d-6d3e6fc963b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.1913"
     ]
    }
   ],
   "source": [
    "#train for 100 epochs\n",
    "fit(100, model, criterion_mse, opt, dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2d072e9-05fe-431d-89b0-3c742def39ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.126470565795898\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "preds = model(inputs)\n",
    "loss = criterion_mse(preds, targets)\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8142315a-e0a5-46b2-825a-ef810ad872ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
